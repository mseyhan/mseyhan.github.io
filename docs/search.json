[
  {
    "objectID": "posts/regression_mean/regression_to_the_mean.html",
    "href": "posts/regression_mean/regression_to_the_mean.html",
    "title": "The Illusion of Form: Regression to the Mean in Football",
    "section": "",
    "text": "There is an evident statistical regularity hidden in plain sight â€” one that, when ignored, quietly shapes football narratives, fuels misjudgments, and silently distorts careers: regression to the mean.\nIf youâ€™re a football fan, like me â€” since the beginning of my childhood â€” big effect of my grandfather being a fan and serving on the council committee of BeÅŸiktaÅŸ JK. And if youâ€™re a football fan, with the pull of confirmation bias, youâ€™re often inclined to validate your teamâ€™s decisions, even when theyâ€™re performing bad. You see what you hope to see. Or sometimes youâ€™re affected by the crowdâ€™s opinion, and make up stories about the bad performance, usually ends up finding a scapegoat, perfect fit for the situation. And boo him/her, maybe?\nAnd in most football clubs â€” especially the ones that are not data-driven or digital-native (which is most of them, outside the privileged few) â€” the decision-making at the management level is often no different from that of the fans. In some contexts, it may even be worse.\nThey, too, seek causality. They crave a clean narrative, and illuminate the ambiguity. But football doesnâ€™t always offer causal clarity. And in that search for meaning, we often miss whatâ€™s actually going on: plain old randomness. It shows up looking like form, momentum, or a player in decline â€” but itâ€™s just luck, really.\nThis post is about that hidden force â€” how it works, how it deceives us, and how it affects players, coaches, analysts, and fans alike.\nWith a simple simulation, some stats, and a bit of honest thinking about how we judge performances, weâ€™re going to break down how luck often looks like talent or failure. And how regression to the mean offers a much-needed antidote.\nLetâ€™s begin there."
  },
  {
    "objectID": "posts/regression_mean/regression_to_the_mean.html#dots-that-deceive-judging-from-one-half",
    "href": "posts/regression_mean/regression_to_the_mean.html#dots-that-deceive-judging-from-one-half",
    "title": "The Illusion of Form: Regression to the Mean in Football",
    "section": "Dots That Deceive â€” Judging from One Half",
    "text": "Dots That Deceive â€” Judging from One Half\nBelow, weâ€™ve plotted ratings from the first half of the season for three distinct groups of players:\n\nğŸŸ¢ Top Performers (highest ratings, seemingly exceptional talent)\nğŸ”µ Average Performers (ratings around the mean, reliably consistent)\nğŸ”´ Worst Performers (lowest ratings, seemingly struggling players)\n\nEach dot represents a playerâ€™s rating. The dashed gray line shows the overall average rating (6.89).\n\n# --- Plot ---\nfig, ax = plt.subplots(figsize=(13, 7))\nplot_custom_dots(ax, best_fh, perspective='fh', reveal_other_half=False, cmap=cm.Greens, norm=norm)\nplot_custom_dots(ax, worst_fh, perspective='fh', reveal_other_half=False, cmap=cm.Reds, norm=norm)\nplot_custom_dots(ax, avg_fh, perspective='fh', reveal_other_half=False, cmap=cm.Blues, norm=norm)\nax.axhline(fh_mean, linestyle='--', color='gray', linewidth=1.2)\nax.text(2.05, fh_mean + 0.1, f'First Half Mean: {fh_mean:.2f}', color='gray', fontsize=10)\nax.set_title('Regression to the Mean\\n(First Half Perspective), with dots', fontsize=16, weight='bold')\n#ax.legend(handles=make_legend(best_fh, avg_fh, worst_fh), loc='lower right', fontsize=11)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/regression_mean/regression_to_the_mean.html#first-half-narratives-exceptional-average-bench-him",
    "href": "posts/regression_mean/regression_to_the_mean.html#first-half-narratives-exceptional-average-bench-him",
    "title": "The Illusion of Form: Regression to the Mean in Football",
    "section": "First-Half Narratives: â€œExceptional!â€ â€œAverageâ€¦â€ â€œBench him!â€",
    "text": "First-Half Narratives: â€œExceptional!â€ â€œAverageâ€¦â€ â€œBench him!â€\nIâ€™ve deliberately hidden these playersâ€™ second-half ratings. Before revealing them, Iâ€™d like you to think deeply about the following questions:\n\nHow do you think these players performed in the second half?\nWho would you trust going forward?\nWho would you praise or criticize based on just this half-season snapshot?\n\nPause here. Consider carefully before continuing. Make explicit or mental judgments based on the data youâ€™ve seen so far.\nI knowâ€”itâ€™s challenging to guess solely from these dots. To help you internalize, let me offer three relatable player narratives corresponding to each of the three groups.\nRight now, you might be thinking something along these lines:\n\nğŸŸ¢ For the top performers:\nâ€œHeâ€™s exceptional! Clearly, a talent we can build around. Heâ€™s the future. We should renew his contract, or if we had to sell him, we should expect extreme amounts!â€\n\n\nğŸ”µ For the average performers:\nâ€œSolid player, but maybe lacking ambition. We need more exciting talentâ€”someone who clearly makes a difference.â€\n\n\nğŸ”´ For the worst performers:\nâ€œHe looks lethargic, uninterested. He simply doesnâ€™t have the mental toughness to succeed at this level. Bench him.â€\n\nThese reactions are natural to the human mind, yet they might also be premature.\nJust about a second when you scroll down, you might encounter something counter-intuitive for you. Below, youâ€™ll see the same playersâ€™ second half performances, too.\n\n\nReveal: Second-Half Performance | When the Curtain Drops â€” Reality Check\n\n# --- Plot ---\nfig, ax = plt.subplots(figsize=(13, 7))\nplot_custom_dots(ax, best_fh, perspective='fh', reveal_other_half=True, cmap=cm.Greens, norm=norm)\nplot_custom_dots(ax, worst_fh, perspective='fh', reveal_other_half=True, cmap=cm.Reds, norm=norm)\nplot_custom_dots(ax, avg_fh, perspective='fh', reveal_other_half=True, cmap=cm.Blues, norm=norm)\nax.axhline(fh_mean, linestyle='--', color='gray', linewidth=1.2)\nax.text(2.05, fh_mean + 0.1, f'First Half Mean: {fh_mean:.2f}', color='gray', fontsize=10)\nax.set_title('Regression to the Mean\\n(First Half Perspective), with dots', fontsize=16, weight='bold')\nax.legend(handles=make_legend(best_fh, avg_fh, worst_fh), loc='lower right', fontsize=11)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFor better tracking, I prepared the observations in a way that lets you follow the players left to right on the x-axis. For example, you can now trace exactly how each top performer ended up performing in the second half, based on our modest simulation.\nAlso, the legend provides the average change in performance for each group â€” which is super useful context.\n\n\nTurns Out, the Story Changesâ€¦\nWhen we reveal the hidden half, something remarkable happens:\n\nğŸŸ¢ Top performers generally decline slightly, not catastrophically, but still, you can observe an evident decline. Also, enough to disappoint inflated expectations.\nğŸ”µ Average players mostly remain stable in average rating. But they ended up going both ways.\nğŸ”´ Worst performers notably improve, challenging the assumptions of incompetence or low motivation.\n\nBut most importantly, they distributed almost homogenously. We donâ€™t see three player categories conserved the distinction between them. This image is a visual representation of regression to the mean in action.\nTo make this transition more intuitive and visually obvious, hereâ€™s another version of the same dataset â€” but this time with arrows connecting the two halves.\nEach arrow shows a playerâ€™s change from first half (dot origin) to second half (arrowhead):\n\nDirection: indicates movement.\nColor: matches the original grouping (green, blue, red).\nLength: shows how much the performance regressed toward the mean."
  },
  {
    "objectID": "posts/regression_mean/regression_to_the_mean.html#arrows-that-regress",
    "href": "posts/regression_mean/regression_to_the_mean.html#arrows-that-regress",
    "title": "The Illusion of Form: Regression to the Mean in Football",
    "section": "Arrows That Regress",
    "text": "Arrows That Regress\n\nHow Everyone Moves Closer to the Mean\n\n# --- Plot ---\nfig, ax = plt.subplots(figsize=(13, 7))\nplot_custom_arrows(ax, best_fh, perspective='fh', reveal_other_half=True, cmap=cm.Greens, norm=norm)\nplot_custom_arrows(ax, worst_fh, perspective='fh', reveal_other_half=True, cmap=cm.Reds, norm=norm)\nplot_custom_arrows(ax, avg_fh, perspective='fh', reveal_other_half=True, cmap=cm.Blues, norm=norm)\nax.axhline(fh_mean, linestyle='--', color='gray', linewidth=1.2)\nax.text(2.05, fh_mean + 0.1, f'First Half Mean: {fh_mean:.2f}', color='gray', fontsize=10)\nax.set_title('Regression to the Mean\\n(First Half Perspective), with arrows', fontsize=16, weight='bold')\nax.legend(handles=make_legend(best_fh, avg_fh, worst_fh), loc='lower right', fontsize=11)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nVisually or mathematically (shown in the legend), I think itâ€™s definitely salient how they got close to the average.\nThis arrow plot gives you an immediate sense of whatâ€™s happening:\n\nMany of the top performers are still good, but theyâ€™ve regressed toward the average.\nThe worst performers? Surprisingly decent now.\nThe average ones? Holding the line.\n\nItâ€™s clear: extreme observations tend to pull back toward the center."
  },
  {
    "objectID": "posts/regression_mean/regression_to_the_mean.html#regression-check-a-slope-that-reveals-the-pull",
    "href": "posts/regression_mean/regression_to_the_mean.html#regression-check-a-slope-that-reveals-the-pull",
    "title": "The Illusion of Form: Regression to the Mean in Football",
    "section": "Regression Check: A Slope That Reveals the Pull",
    "text": "Regression Check: A Slope That Reveals the Pull\nWhile our simulation illustrates how extremes tend to drift toward the average, we can also show it quantitatively via a simple linear regression. If we take each playerâ€™s first-half performance as a predictor and plot their second-half performance against it, we can fit a regression line to see how well one half predicts the other.\nSpecifically, if we take each playerâ€™s first-half rating as an independent variable (predictor) and second-half rating as the dependent variable (outcome), we typically see a regression slope less than 1. In a perfectly consistent world, the dots would fall on a 45-degree diagonal line â€” where every extreme performance repeats itself. That diagonal has a slope of 1.\nIn a simple linear regression of; \\[\\text{Second-Half Performance} = \\text{ a } x \\text{ b } x \\text{ First-Half Performance } \\] the coefficient b (the â€œslopeâ€) tells us how strongly the second-half scores scale with the first-half scores. A slope of 1 would mean that a player 1 point above average in the first half is predicted to be exactly 1 point above average in the second half. In other words, there would be no â€œpullâ€ back toward the average.\nBut, because of the luck factors, the line we actually get isnâ€™t that steep. Itâ€™s flatter. In our simulation, the regression line has a slope less than 1 because we added luck factor to true skill. That number might seem small, but itâ€™s doing something big:\nThat number might seem small, but itâ€™s doing something big:\n\nIt pulls high performers down: If someone was far above average in the first half, the regression line predicts theyâ€™ll be closer to average in the second half.\nIt pulls low performers up: If someone struggled early, it suggests theyâ€™ll bounce back â€” also drifting toward the middle.\n\nCheck this plot out:\n\nfig, ax = plot_regression_with_highlighted_groups(df, best_fh, worst_fh, avg_fh)\nplt.show()\n\n\n\n\n\n\n\n\nWhy does that happen? Because football performance â€” like many things in life â€” is a mix of skill and randomness. And since randomness is unpredictable, the correlation between the two halves isnâ€™t perfect. The slope reflects that imperfection. The less perfect the link, the more the extremes â€œshrinkâ€ toward the average. Thatâ€™s regression to the mean in action â€” visualized."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Murat Seyhan, Data Scientist",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nThinking in Distributions in Football\n\n\n\nFootball Analytics\n\n\n\nWhy does intuition mislead us in complex decisions? We simulate the â€œdanceâ€ of the p-value using 2015â€“2016 Premier League xG data and talk about power, sample size, and noise.\n\n\n\n\n\nMurat Seyhan\n\n\n\n\n\n\n\n\n\n\n\n\nThe Illusion of Form: Regression to the Mean in Football\n\n\n\nFootball Analytics\n\n\n\nExtreme performances catch headlines. But behind the highs and lows lies a quieter truth: randomness. This post unpacks how regression to the mean fools fans, coaches, and analysts â€” and how to see through the illusion.\n\n\n\n\n\nMurat Seyhan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, Iâ€™m Murat Seyhan, a data scientist with a passion for the sea. Iâ€™ve always believed that life is a blend of structure and flow, much like the balance between my gusto for data and the open sea. Let me introduce myself in a few words.\n\nDATA SCIENCE\nProfessionally, Iâ€™m a Data Scientist, where Iâ€™ve specialized in discovering patterns in chaos. Essentially itâ€™s really just a fancy way of saying I help make sense of things that seem too big or complicated for our intuition. From predictive analytics to crafting intuitive dashboards, Iâ€™ve always sought to make complex data tell a clear story. Along the way, Iâ€™ve had the chance to work on projects that transformed raw numbers into actionable insights, gaining valuable experience at organizations like Garanti BBVA and KPMG.\n\n\nFOOTBALL ANALYTICS\nOne of my recent passions is football analytics. Using Python, I dive into match data to uncover insights and create visualizations. Iâ€™m working on ways to bring these analyses to a wider audience, bringing together my interest in sports and data.\n\n\nSAILING ADVENTURES\nDuring my university years, I found myself not just studying Economics but working as a sailing instructor, teaching students of all levelsâ€”from beginners to competitive racersâ€”how to handle boats and embrace the wind. This role was deeply fulfilling, combining my love for the sport with the joy of teaching. At the same time, I founded a Sailing Club in Marmara University, creating a vibrant community of students who bonded over the wind and waves. Leading such a community of students was a defining experienceâ€”teaching and learning from others, both on the water and off.\n\n\nMUSIC & CREATIVITY\nWhen Iâ€™m not immersed in data or the sea, I turn to music for a creative outlet. Playing the guitar, performing live, or producing melodies has been a part of my life since 2014. Itâ€™s my way of expressing creativity and connecting with others.\nThis is me in a snapshotâ€”someone who finds joy in analyzing data, navigating the seas, creating music, and exploring football through numbers. If any of this resonates, Iâ€™d love to connect and share more!"
  },
  {
    "objectID": "posts/think_distributions/thinking_in_distributions.html",
    "href": "posts/think_distributions/thinking_in_distributions.html",
    "title": "Thinking in Distributions in Football",
    "section": "",
    "text": "Iâ€™ve been kind of obsessed with decision-making for a while. I think human intuition, by its nature, is weak when it comes to making decisions in high-dimensional problems. Even if we can make â€œprimitiveâ€ decisions very comfortably, in complex problems our intuitive decision-making isnâ€™t that different from random choices. The environment matters a lot here, too. If we work in an area where our actions produce highly regular and fast feedback, then we can trust our intuition more.\nThereâ€™s no complete cure for biases and mental shortcuts; weâ€™re all vulnerable to them. But by building certain habits, we can still pave the way to making better decisions overall. Most of the times I felt like I got better at decision-making were the times I acted by not trusting my intuition on many things. While picking up new habits, I tried to lean on statistical ways of thinking. Iâ€™m also aware I still have a long way to go.\nAnd like everyone else, as I walk this road, I understand what Iâ€™m working on more easily through examples from daily life. Thatâ€™s why, in what I write, I often try to use context discovery and analogy. Itâ€™s useful to map the decisions I make in different areas of my life onto what Iâ€™ve learned. And for the next decision, I try to make each new way of thinking more â€œnativeâ€ to me. Being able to develop skills that transfer across contexts matters.\nThe observation bank Iâ€™ve built from working in data analytics for about 5 years pushed me to question some of the intuitive choices that are used a lot in the field. The topic I sat down to write about in this blog is one of those widely used â€œrules of thumbâ€: the â€œp-valueâ€.\n\nThe most basic problem with the p-value is this: most of the time we use it as â€œa one-shot decision labelâ€. But even though the p-value lands in our hands as a single number, it carries variability behind it; even under the same true effect, if you measure again and again with different samples, sometimes p comes out small, sometimes large. In the previous post, when I said â€œextremes misleadâ€, what I meant was treating a single observation as the whole universe. Here weâ€™ll carry the same idea to a different place: a single p doesnâ€™t have to represent reality. Sometimes, just with bad luck, it looks â€œinsignificantâ€; sometimes, with good luck, it looks â€œvery significantâ€. So the p-value kind of dances. And from what I can see, this conceptâ€”now a very common one in data analyticsâ€”often gets used as a one-shot decision label by ignoring its dance.\nIn this post, to make things more intuitive and easier to understand, Iâ€™ll let the reader watch two separate â€œuniversesâ€; think of it as if the same movie has two different versions.\nIn the first universe, there is the H0 world: in reality there is no difference between two things, meaning there is no signal to catch.\nIn the second universe, there is the H1 world: in reality there is a difference, but because of signal strength and the level of noise, it doesnâ€™t show up with the same clarity in every measurement.\nThe same p-value idea behaves very differently in these two worlds: in one, false alarms are â€œnaturalâ€; in the other, even though there is a real signal, itâ€™s â€œnormalâ€ that sometimes the alarm doesnâ€™t ring. When I put these two universes side by side, I started reading the p-value not as a result stamp, but as a frequency idea that helps us tune our intuitive decisions.\n\n\n\n\n\n\nNoteNotes on the method and which data weâ€™ll use\n\n\n\n\n\nAt this point I donâ€™t want to leave the abstract concepts hanging in the air; because my whole point is already this â€œintuitive decisionâ€ thing. In real life, when we make decisions, most of the time we donâ€™t have a single experiment in our handsâ€”there are lots of small observations, an uncertain signal, and noisy results. Football is a perfect lab in this sense: first, everyone has an opinion :), the data is abundant, but decisions (player form, transfers, coaching changes) are often made by leaning on single matches or short runs. So football data is a good ground for showing how â€œsingle numbersâ€ like the p-value can mislead us.\nWhile showing this, I wanted to use real football data. StatsBombâ€™s Open Data set openly shares event-level data for some leagues and tournaments. This whole blog will be a sanity-check of an idea that can be reproduced easily, and Iâ€™ll use the Premier League 2015â€“16 season. The story of that season is extremely strong (Leicesterâ€™s title), and because I followed it live back then, the context is still vivid in my head. Instead of abstract A/B examples, I think itâ€™s easier to place what weâ€™re trying to measure into a world everyone can picture.\nTechnically, in Python we connect to Open Data with statsbombpy and pull the seasonâ€™s matches; then we take the shots from each matchâ€™s event data and use the expected goals value per shot (shot_statsbomb_xg). As you know, this metric is both a common reference point in modern football and, because itâ€™s closer to a process measure than the outcome (goal/no goal), it reduces noise. In the simulations youâ€™ll see later, weâ€™ll use this shot-xG distribution and pretend weâ€™re asking the same question again and again: â€œIs the average shot quality of these two groups really different?â€ Thatâ€™s where the p-valueâ€™s dance becomes much more visible on this noisy sample coming from real football."
  },
  {
    "objectID": "posts/think_distributions/thinking_in_distributions.html#where-do-we-make-the-wrong-decisions",
    "href": "posts/think_distributions/thinking_in_distributions.html#where-do-we-make-the-wrong-decisions",
    "title": "Thinking in Distributions in Football",
    "section": "Where do we make the wrong decisions?",
    "text": "Where do we make the wrong decisions?\nPut simply: we treat a single sample as if it were the distribution.\nMaybe p-value isnâ€™t a concept we use in daily life a lot, but every time we â€œdetectâ€ a difference or an effect in our head, weâ€™re basically running a p-value-like process. We think what we saw is different from normal, and we kick off a test in our mind according to our norms. If the difference looks big to us, and it sits farther from the general deviation of the norms around us, we call it â€œsignificantâ€. But usually this comes from a single or just a handful of observations.\nWhen I started seeing the p-value not as a â€œsingle outcomeâ€ but as â€œthe output of a repeatable processâ€, I began thinking that most of the time weâ€™re just overreacting to noise randomly showing up in front of us. Yet we use it as the basis for character analysis, form diagnosis, even million-euro decisions.\nI think there are common pattern mistakes we fall into, for example:\n\n- We do character analysis off a single big match\nHe managed the derby badly, we lost. â†’ â€œHeâ€™s not a big-match coach.â€\nThis is a problematic read because â€œderby performanceâ€ contains a ton of randomness inside it. An early conceded goal, a referee decision, one or two critical turnoversâ€¦ Instead of measuring someoneâ€™s true level, we take a single draw from the distribution (that dayâ€™s realization) and do a personality analysis.\n\n\n- We get overly attached to the score or results\nHe scored 2 goals â†’ â€œin form.â€\nGoals are one of the noisiest outputs in football. But most of the time we worship the outcome and ignore the process: where the shot came from, shot quality (xG), the playerâ€™s role, the context in which the team gets him into that positionâ€¦ We used xG (shot_statsbomb_xg) for exactly this reason: itâ€™s a good example of a process metric thatâ€™s closer to the shotâ€™s â€œdangerâ€ level, independent of whether it turned into a goal.\n\n\n- We make expensive decisions off a short run\n10â€“15 matches â†’ â€œsell / loan / sack the coach.â€\nThis means making expensive decisions, in the context we described above, with a â€œlow-power measurementâ€. In the SÃ¼per Lig, sometimes you see a coaching change every 10 matches. A 10-match run is a tiny window inside footballâ€™s noise. What we see here is often not true performance, but deviations coming from randomness.\nFor example, BozzStats has a visualization that always makes me laugh.\nBozzStats â€œHocamâ€ Chart"
  },
  {
    "objectID": "posts/think_distributions/thinking_in_distributions.html#how-does-this-help-us-make-better-decisions",
    "href": "posts/think_distributions/thinking_in_distributions.html#how-does-this-help-us-make-better-decisions",
    "title": "Thinking in Distributions in Football",
    "section": "How does this help us make better decisions?",
    "text": "How does this help us make better decisions?\nLike I mentioned before, trying to develop skills that transfer across contexts is really important. We can use this idea while building small reflexes to make better decisions.\n\n- Quit the habit of deciding with a tiny sample (1â€“5 decision points)\nInstead of passing judgment from a single match, build the habit of slowing yourself down with: â€œIn what kind of series am I seeing this performance?â€ Questions to think with:\n\nIs the same player making similar decisions in similar roles, against similar opponents?\nDid the conditions change? (role, injury, tactics, match flow)\n\nIn p-value language, this means: donâ€™t decide with a single p; look for repeatability in the process.\n\n\n- Raise the evidence threshold for expensive decisions\nAs the cost of a decision goes up, you should raise your â€œevidenceâ€ threshold too.\n\nDecisions like sacking a coach / selling a player / giving a big contract shouldnâ€™t be made off a one-match feeling, but with a stronger signal and a more solid sample.\n\nYou can do this by keeping the n=5 experiment in the notebook in mind. When the sample shrinks, power drops, and it becomes harder to see a clear result â€œeven when there is an effectâ€. For expensive decisions, thatâ€™s not a risk we want to take.\n\n\n- Try to use process metrics instead of outcome metrics\nInstead of making decisions with outcome metrics like goals/points, process metrics (xG, shot quality, passing connections, pressing actions, carrying the ball into the final third, etc.) can give more stable signals.\nIn general, focusing on improving the process and waiting for the results to follow can be healthier than getting overly attached to single outcomes."
  }
]